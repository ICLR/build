<!doctype html>
<html lang="en">
  
  <head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="stylesheet" href="static/css/main.css">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
    integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
    integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
  <script src="static/js/typeahead.bundle.js"></script>
  <link rel="stylesheet" href="static/css/typeahead.css">
  <link rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
    crossorigin="anonymous">
  <link rel="stylesheet" href="static/css/lazy_load.css">
  <script src="static/js/lazy_load.js"></script>
  <title> ICLR: Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention </title>
</head>
  <body >
    <!-- NAV -->
    
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.24.0/moment.min.js"
  integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
  crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/moment-timezone/0.5.28/moment-timezone-with-data.min.js"
  integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww="
  crossorigin="anonymous"></script>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
    <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          
          <a class="nav-link" href="index.html">Home</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="calendar.html">Schedule</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="workshops.html">Workshops</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="papers.html">Papers</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" target="_blank" href="https://iclr.6connex.com/event/VirtualEvent/">
            <nobr>Sponsor Hall <svg class="bi bi-box-arrow-up-right" width="1em" height="1em" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
    <path fill-rule="evenodd" d="M1.5 13A1.5 1.5 0 003 14.5h8a1.5 1.5 0 001.5-1.5V9a.5.5 0 00-1 0v4a.5.5 0 01-.5.5H3a.5.5 0 01-.5-.5V5a.5.5 0 01.5-.5h4a.5.5 0 000-1H3A1.5 1.5 0 001.5 5v8zm7-11a.5.5 0 01.5-.5h5a.5.5 0 01.5.5v5a.5.5 0 01-1 0V2.5H9a.5.5 0 01-.5-.5z" clip-rule="evenodd"/>
    <path fill-rule="evenodd" d="M14.354 1.646a.5.5 0 010 .708l-8 8a.5.5 0 01-.708-.708l8-8a.5.5 0 01.708 0z" clip-rule="evenodd"/>
</svg></nobr>
          </a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="socials.html">Socials</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="chat.html">Chat</a>
          
        </li>
        
        <li class="nav-item ">
          
          <a class="nav-link" href="about.html">Help</a>
          
        </li>
        
      </ul>
    </div>
  </div>
</nav>
    <div class="container">
      <!-- Title -->
      <div class="pp-card m-3" style="">
        <div class="card-header">
          <h2 class="card-title main-title text-center" style="">
            Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention
          </h2>
          <h3 class="card-subtitle mb-2 text-muted text-center">
            
            <a href="papers.html?filter=authors&search=Chen Zhao" class="text-muted">Chen Zhao</a>,
            
            <a href="papers.html?filter=authors&search=Chenyan Xiong" class="text-muted">Chenyan Xiong</a>,
            
            <a href="papers.html?filter=authors&search=Corby Rosset" class="text-muted">Corby Rosset</a>,
            
            <a href="papers.html?filter=authors&search=Xia Song" class="text-muted">Xia Song</a>,
            
            <a href="papers.html?filter=authors&search=Paul Bennett" class="text-muted">Paul Bennett</a>,
            
            <a href="papers.html?filter=authors&search=Saurabh Tiwary" class="text-muted">Saurabh Tiwary</a>
            
          </h3>
          <p class="card-text text-center"><span class="">Keywords:</span>
            
            <a href="papers.html?filter=keywords&search=reasoning" class="text-secondary text-decoration-none">reasoning</a>,
            
            <a href="papers.html?filter=keywords&search=question answering" class="text-secondary text-decoration-none">question answering</a>,
            
            <a href="papers.html?filter=keywords&search=attention" class="text-secondary text-decoration-none">attention</a>,
            
            <a href="papers.html?filter=keywords&search=nlp" class="text-secondary text-decoration-none">nlp</a>,
            
            <a href="papers.html?filter=keywords&search=multi hop qa" class="text-secondary text-decoration-none">multi hop qa</a>,
            
            <a href="papers.html?filter=keywords&search=transformer" class="text-secondary text-decoration-none">transformer</a>,
            
            <a href="papers.html?filter=keywords&search=verification" class="text-secondary text-decoration-none">verification</a>,
            
            <a href="papers.html?filter=keywords&search=fact verification" class="text-secondary text-decoration-none">fact verification</a>
            
          </p>
          <div class="text-center p-3">
            <a class="card-link" data-toggle="collapse" role="button" href="#details">
            Abstract
            </a>
            <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf?id=r1eIiCNYwS">
            Paper
            </a>
            
            <a href="https://drive.google.com/file/d/1-CwjDwSvGzLKHMXNapzTin8Vw6SVYD9b/view?usp=sharing" target="_blank"  class="card-link">
            Code
            </a>
            
            <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=r1eIiCNYwS">
            Reviews
            </a>
            <!--  -->
            <!-- <a href="" target="_blank"  class="card-link"> -->
            <!--   Slides -->
            <!-- </a> -->
            <!--  -->
            <!-- </div> -->
            <!-- <div class="text-center "> -->
            <a href="chat.html?room=channel/poster_508" target="_blank"  class="card-link">
            Chat
            </a>
          </div>
          <div class=" text-center text-muted text-monospace">
            
            <div> Mon Session 1  <span class="session_times">(05:00-07:00 GMT)</span>
              [<a href="https://us02web.zoom.us/j/87928509527?pwd=MUF1dnN4UXkxeGhtcWwrWnZnSmlCUT09" target="_blank"  class="card-link">Live</a>] 
            </div>
            
            <div> Mon Session 3  <span class="session_times">(12:00-14:00 GMT)</span>
              [<a href="https://us02web.zoom.us/j/87957919177?pwd=ek9maVZ1aEY1YVVxUVlQWEtmMUJGZz09" target="_blank"  class="card-link">Live</a>] 
            </div>
            
          </div>
        </div>
      </div>
      <div id="details" class="pp-card m-3 collapse">
        <div class="card-body">
          <p class="card-text">
          <div id="abstractExample">
            <span class="font-weight-bold">Abstract:</span>
            Transformers have achieved new heights modeling natural language as a sequence of text tokens. However, in many real world scenarios, textual data inherently exhibits structures beyond a linear sequence such as trees and graphs; many tasks require reasoning with evidence scattered across multiple pieces of texts. This paper presents Transformer-XH, which uses eXtra Hop attention to enable intrinsic modeling of structured texts in a fully data-driven way. Its new attention mechanism naturally “hops” across the connected text sequences in addition to attending over tokens within each sequence. Thus, Transformer-XH better conducts joint multi-evidence reasoning by propagating information between documents and constructing global contextualized representations. On multi-hop question answering, Transformer-XH leads to a simpler multi-hop QA system which outperforms previous state-of-the-art on the HotpotQA FullWiki setting. On FEVER fact verification, applying Transformer-XH provides state-of-the-art accuracy and excels on claims whose verification requires multiple evidence.
          </div>
          </p>
          <p></p>
        </div>
      </div>
    </div>
    <!-- SlidesLive -->
    <div class="container" style="background-color:white; padding: 0px;">
      <div class="row m-2">
        <div class="col-md-7 col-xs-12 my-auto p-2" >
          (Note: This video is a temporary placeholder.)

          <div id="presentation-embed-38915748" class="slp my-auto"></div>
          <script src='https://slideslive.com/embed_presentation.js'></script>
          <script>
            embed = new SlidesLiveEmbed('presentation-embed-38915748', {
            presentationId: '38915748',
            autoPlay: false, // change to true to autoplay the embedded presentation
            verticalEnabled: true,
            verticalWhenWidthLte: 2000,
            allowHiddenControlsWhenPaused: true,
            hideTitle: true
            });
          </script>
        </div>
        <div class="col-md-5 col-xs-12 p-2">
          <div id="gitter" class="slp">
            <center>
              <iframe frameborder="0" src="https://iclr.rocket.chat/channel/poster_508?layout=embedded" height="700px" width="100%" ></iframe>
            </center>
          </div>
        </div>
      </div>
    </div>

    <!-- Recs -->
    <p></p>
    <div  class="container" style="padding-bottom: 30px; padding-top:30px">
      <center>
        <h2> Similar Papers </h2>
      </center>
    </div>
    <p></p>
    <div  class="container" >
      <div class="row">
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_ByeMPlHKPH.html" class="text-muted">
                <h5 class="card-title" align="center">Lite Transformer with Long-Short Range Attention</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Zhanghao Wu,
                
                Zhijian Liu,
                
                Ji Lin,
                
                Yujun Lin,
                
                Song Han,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/ByeMPlHKPH.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_SJgVHkrYDH.html" class="text-muted">
                <h5 class="card-title" align="center">Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Akari Asai,
                
                Kazuma Hashimoto,
                
                Hannaneh Hajishirzi,
                
                Richard Socher,
                
                Caiming Xiong,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJgVHkrYDH.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_ByxY8CNtvr.html" class="text-muted">
                <h5 class="card-title" align="center">Improving Neural Language Generation with Spectrum Control</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Lingxiao Wang,
                
                Jing Huang,
                
                Kevin Huang,
                
                Ziniu Hu,
                
                Guangtao Wang,
                
                Quanquan Gu,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/ByxY8CNtvr.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
        <div class="col-md-4 col-xs-6">
          <div class="pp-card" >
            <div class="pp-card-header" class="text-muted">
              <a href="poster_ByxRM0Ntvr.html" class="text-muted">
                <h5 class="card-title" align="center">Are Transformers universal approximators of sequence-to-sequence functions?</h5>
              </a>
              <h6 class="card-subtitle text-muted" align="center">
                
                Chulhee Yun,
                
                Srinadh Bhojanapalli,
                
                Ankit Singh Rawat,
                
                Sashank Reddi,
                
                Sanjiv Kumar,
                
              </h6>
              <center><img class="cards_img" src="https://iclr.github.io/iclr-images/ByxRM0Ntvr.png" width="80%"/></center>
            </div>
          </div>
        </div>
        
      </div>
    </div>
    <script type="text/javascript">
  $(document).ready(function () {
  
  if (location.hash !== '') {
  $('a[href="' + location.hash + '"]').tab('show');
  }
  
  $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
  var hash = $(e.target).attr("href");
  if (hash.substr(0,1) == "#") {
  var position = $(window).scrollTop();
  location.replace("#" + hash.substr(1));
  $(window).scrollTop(position);
  }
  });
  
  });
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-163955028-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  
  gtag('config', 'UA-163955028-1');
</script>
<footer class="footer bg-light p-4">
  <div class="container">
    <p class="float-right"><a href="#">Back to Top</a></p>
    <p class="text-center">© 2020 International Conference on Learning Representations</p>
  </div>
</footer>
  </body>
  <script src="static/js/time-extend.js"></script>
<script>
  $(document).ready(()=>{
    add_local_tz('.session_times');
  })
</script>
</html>