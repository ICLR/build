<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">



    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Improved memory in recurrent neural networks with sequential non-normal dynamics </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>

<style>
  body{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .jumbotron{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .btn-group{background-color: white}
  .btn {background-color: white}
  #main-nav {padding-top:10px; padding-bottom:10px;}
  .card {font-family: 'Exo'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);}
  .header {font: "Montserrat"; }
  .card-header { border: 4px solid #eee;
                font-family: "Exo";}

  
  .main-title {font-weight: 700;  color: #2294e0;}

  .myAccordion {

  box-shadow: 0px 2px 14px 0px rgba(0, 0, 0, 0.10);
    border-radius: 10px;
    margin-bottom: 18px;
    padding-left: 15px;
    padding-bottom: 10px;
    padding-right: 15px;
    padding-top: 10px;
    background-color: rgba(255, 255, 255, 1);
  }

  .sponsorLogo {
  width: 250px;
  display: block;
  margin-left: auto;
    margin-right: auto;
  margin-top: auto;
    margin-bottom: auto;

  }
  
  .slp {

  background: #fff

  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  .border {
  background: #fff
  
  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  #abstractExample.collapse:not(.show) {
  display: block;
  /* height = lineheight * no of lines to display */
  height: 4.5em;
  overflow: hidden;
  }

  #abstractExample.collapsing {
  height: 4.5em;
  }


#absShow.collapsed:after {
  content: '+ Show More';
}

#absShow:not(.collapsed):after {
  content: '- Show Less';
}
</style>


<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="livestream.html">Live</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="speakers.html">Speakers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">FAQ</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       Improved memory in recurrent neural networks with sequential non-normal dynamics
     </h3>
     
     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Emin Orhan,
       
       Xaq Pitkow
       
     </h5>
     
     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>
       

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/ab961c1482531ce058d1a2ea78235c2128c80853.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=ryx1wRNFvB">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>
       
       <a href="https://github.com/eminorhan/nonnormal-init" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Code
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Slides
         </button>
       </a>
     </center>
     
   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Training recurrent neural networks (RNNs) is a hard problem due to degeneracies in the optimization landscape, a problem also known as vanishing/exploding gradients. Short of designing new RNN architectures, previous methods for dealing with this problem usually boil down to orthogonalization of the recurrent dynamics, either at initialization or during the entire training period. The basic motivation behind these methods is that orthogonal transformations are isometries of the Euclidean space, hence they preserve (Euclidean) norms and effectively deal with vanishing/exploding gradients. However, this ignores the crucial effects of non-linearity and noise. In the presence of a non-linearity, orthogonal transformations no longer preserve norms, suggesting that alternative transformations might be better suited to non-linear networks. Moreover, in the presence of noise, norm preservation itself ceases to be the ideal objective. A more sensible objective is maximizing the signal-to-noise ratio (SNR) of the propagated signal instead. Previous work has shown that in the linear case, recurrent networks that maximize the SNR display strongly non-normal, sequential dynamics and orthogonal networks are highly suboptimal by this measure. Motivated by this finding, here we investigate the potential of non-normal RNNs, i.e. RNNs with a non-normal recurrent connectivity matrix, in sequential processing tasks. Our experimental results show that non-normal RNNs outperform their orthogonal counterparts in a diverse range of benchmarks. We also find evidence for increased non-normality and hidden chain-like feedforward motifs in trained RNNs initialized with orthogonal recurrent connectivity matrices. 
       </div>
       
     </p>
     
     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="keyword_recurrent neural networks.html" class="text-secondary text-decoration-none">recurrent neural networks</a>,
       
       <a href="keyword_memory.html" class="text-secondary text-decoration-none">memory</a>,
       
       <a href="keyword_non-normal dynamics.html" class="text-secondary text-decoration-none">non-normal dynamics</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



<div class="container ">
  <div class="row m-2">
    <div class="col-7">
      <div id="presentation-embed-38915748" class="slp"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        allowHiddenControlsWhenPaused: true,
        zoomRatio: 0.4,
        hideTitle: true
        });
      </script>
    </div>
    
    <div class="col-5 p-1 my-auto">        
        <div id="gitter" class="gitter container " >
          <center>
            <div class="border">
              <center> <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_ryx1wRNFvB?layout=embedded" width="100%" height="680px"></iframe> </center>
            </div>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
  

      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_HylpqA4FwS.html" class="text-dark"><h5 class="card-title">RNNs Incrementally Evolving on an Equilibrium Manifold: A Panacea for Vanishing and Exploding Gradients?</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/HylpqA4FwS.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Incremental-RNNs resolves exploding/vanishing gradient problem by updating state vectors based on difference between previous state and that predicted by an ODE.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_SJgmR0NKPr.html" class="text-dark"><h5 class="card-title">Training Recurrent Neural Networks Online by Learning Explicit State Variables</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/SJgmR0NKPr.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Recurrent neural networks (RNNs) allow an agent to construct a state-representation from a stream of experience, which is essential in partially observable problems. However, there are two primary issues one must overcome when training an RNN: the se...</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_rkg1ngrFPr.html" class="text-dark"><h5 class="card-title">Information Geometry of Orthogonal Initializations and Training</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/rkg1ngrFPr.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> nearly isometric DNN initializations imply low parameter space curvature, and a lower condition number, but that&#39;s not always great</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_rkgqN1SYvr.html" class="text-dark"><h5 class="card-title">Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/rkgqN1SYvr.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We provide for the first time a rigorous proof that orthogonal initialization speeds up convergence relative to Gaussian initialization, for deep linear networks.</p>
            
          </div>      
        </div>
      </div>
      
  </DIV>
</DIV>

</body>