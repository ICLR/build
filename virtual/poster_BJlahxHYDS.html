<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Conservative Uncertainty Estimation By Fitting  Prior Networks </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Browse</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="events.html">Events</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Booths</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="about.html">About</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       Conservative Uncertainty Estimation By Fitting  Prior Networks
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Kamil Ciosek,
       
       Vincent Fortuin,
       
       Ryota Tomioka,
       
       Katja Hofmann,
       
       Richard Turner
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/523d0ff6817176db2a8897bf673b70ca56eb81c8.pdf">
           Paper
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=BJlahxHYDS">
           OpenReview
       </a>

     <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Zoom
       </a>

       <a href="https://iclr.rocket.chat/channel/paper_channel_BJlahxHYDS" target="_blank"  class="card-link">
           Chat
       </a>

       

       
     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Obtaining high-quality uncertainty estimates is essential for many applications of deep neural networks. In this paper, we theoretically justify a scheme for estimating uncertainties, based on sampling from a prior distribution. Crucially, the uncertainty estimates are shown to be conservative in the sense that they never underestimate a posterior uncertainty obtained by a hypothetical Bayesian algorithm. We also show concentration, implying that the uncertainty estimates converge to zero as we get more data. Uncertainty estimates obtained from random priors can be adapted to any deep network architecture and trained using standard supervised learning pipelines. We provide experimental evaluation of random priors on calibration and out-of-distribution detection on typical computer vision tasks, demonstrating that they outperform deep ensembles in practice.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=uncertainty quantification" class="text-secondary text-decoration-none">uncertainty quantification</a>,
       
       <a href="papers.html?filter=keywords&search=deep learning" class="text-secondary text-decoration-none">deep learning</a>,
       
       <a href="papers.html?filter=keywords&search=Gaussian process" class="text-secondary text-decoration-none">Gaussian process</a>,
       
       <a href="papers.html?filter=keywords&search=epistemic uncertainty" class="text-secondary text-decoration-none">epistemic uncertainty</a>,
       
       <a href="papers.html?filter=keywords&search=random network" class="text-secondary text-decoration-none">random network</a>,
       
       <a href="papers.html?filter=keywords&search=prior" class="text-secondary text-decoration-none">prior</a>,
       
       <a href="papers.html?filter=keywords&search=Bayesian inference" class="text-secondary text-decoration-none">Bayesian inference</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_BJlahxHYDS?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BJxI5gHKDr.html" class="text-muted">
              <h5 class="card-title" align="center">Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep Learning</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Arsenii Ashukha,
              
              Alexander Lyzhov,
              
              Dmitry Molchanov,
              
              Dmitry Vetrov,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BJxI5gHKDr.png" width="80%"/></center>

            <!-- <p class="card-text"> We highlight the problems with common metrics of in-domain uncertainty and perform a broad study of modern ensembling techniques.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BygSP6Vtvr.html" class="text-muted">
              <h5 class="card-title" align="center">Ensemble Distribution Distillation</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Andrey Malinin,
              
              Bruno Mlodozeniec,
              
              Mark Gales,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BygSP6Vtvr.png" width="80%"/></center>

            <!-- <p class="card-text"> We distill an ensemble of models into a single model, capturing both the improved classification performance and information about the diversity of the ensemble, which is useful for uncertainty estimation.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rkxNh1Stvr.html" class="text-muted">
              <h5 class="card-title" align="center">Quantifying Point-Prediction Uncertainty in Neural Networks via Residual Estimation with an I/O Kernel</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Xin Qiu,
              
              Elliot Meyerson,
              
              Risto Miikkulainen,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rkxNh1Stvr.png" width="80%"/></center>

            <!-- <p class="card-text"> Learning to Estimate Point-Prediction Uncertainty and Correct Output in Neural Networks</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_ryloogSKDS.html" class="text-muted">
              <h5 class="card-title" align="center">Deep Orientation Uncertainty Learning based on a Bingham Loss</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Igor Gilitschenski,
              
              Roshni Sahoo,
              
              Wilko Schwarting,
              
              Alexander Amini,
              
              Sertac Karaman,
              
              Daniela Rus,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/ryloogSKDS.png" width="80%"/></center>

            <!-- <p class="card-text"> A method for learning to predict uncertainties over orientations using the Bingham Distribution</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>