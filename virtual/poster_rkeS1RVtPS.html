<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">



    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>

<style>
  body{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .jumbotron{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .btn-group{background-color: white}
  .btn {background-color: white}
  #main-nav {padding-top:10px; padding-bottom:10px;}
  .card {font-family: 'Exo'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);}
  .header {font: "Montserrat"; }
  .card-header { border: 4px solid #eee;
                font-family: "Exo";}

  
  .main-title {font-weight: 700;  color: #2294e0;}

  .myAccordion {

  box-shadow: 0px 2px 14px 0px rgba(0, 0, 0, 0.10);
    border-radius: 10px;
    margin-bottom: 18px;
    padding-left: 15px;
    padding-bottom: 10px;
    padding-right: 15px;
    padding-top: 10px;
    background-color: rgba(255, 255, 255, 1);
  }

  .sponsorLogo {
  width: 250px;
  display: block;
  margin-left: auto;
    margin-right: auto;
  margin-top: auto;
    margin-bottom: auto;

  }
  
  .slp {

  background: #fff

  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  .border {
  background: #fff
  
  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  #abstractExample.collapse:not(.show) {
  display: block;
  /* height = lineheight * no of lines to display */
  height: 4.5em;
  overflow: hidden;
  }

  #abstractExample.collapsing {
  height: 4.5em;
  }


#absShow.collapsed:after {
  content: '+ Show More';
}

#absShow:not(.collapsed):after {
  content: '- Show Less';
}
</style>


<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="livestream.html">Live</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="speakers.html">Speakers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">FAQ</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning
     </h3>
     
     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Ruqi Zhang,
       
       Chunyuan Li,
       
       Jianyi Zhang,
       
       Changyou Chen,
       
       Andrew Gordon Wilson
       
     </h5>
     
     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>
       

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/64c55a88ec29d1a60c09e7c647867c3056e1cd83.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=rkeS1RVtPS">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Code
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Slides
         </button>
       </a>
     </center>
     
   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         The posteriors over neural network weights are high dimensional and multimodal. Each mode typically characterizes a meaningfully different representation of the data. We develop Cyclical Stochastic Gradient MCMC (SG-MCMC) to automatically explore such distributions. In particular, we propose a cyclical stepsize schedule, where larger steps discover new modes, and smaller steps characterize each mode. We prove non-asymptotic convergence theory of our proposed algorithm. Moreover, we provide extensive experimental results, including ImageNet, to demonstrate the effectiveness of cyclical SG-MCMC in learning complex multimodal distributions, especially for fully Bayesian inference with modern deep neural networks.
       </div>
       
     </p>
     
     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



<div class="container ">
  <div class="row m-2">
    <div class="col-7">
      <div id="presentation-embed-38915748" class="slp"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        allowHiddenControlsWhenPaused: true,
        zoomRatio: 0.4,
        hideTitle: true
        });
      </script>
    </div>
    
    <div class="col-5 p-1 my-auto">        
        <div id="gitter" class="gitter container " >
          <center>
            <div class="border">
              <center> <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_rkeS1RVtPS?layout=embedded" width="100%" height="680px"></iframe> </center>
            </div>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
  

      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_BJgnXpVYwS.html" class="text-dark"><h5 class="card-title">Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/BJgnXpVYwS.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Gradient clipping provably accelerates gradient descent for non-smooth non-convex functions.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_HJepXaVYDr.html" class="text-dark"><h5 class="card-title">Stochastic AUC Maximization with Deep Neural Networks</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/HJepXaVYDr.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> The paper designs two algorithms for the stochastic AUC maximization problem with state-of-the-art complexities when using deep neural network as predictive model, which are also verified by empirical studies.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_S1gEIerYwH.html" class="text-dark"><h5 class="card-title">Transferring Optimality Across Data Distributions via Homotopy Methods</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/S1gEIerYwH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We propose a new homotopy-based method to transfer &#34;optimality knowledge&#34; across different data distributions in order to speed up training of deep models.  </p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_BkeoaeHKDS.html" class="text-dark"><h5 class="card-title">Gradients as Features for Deep Representation Learning</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/BkeoaeHKDS.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Given a pre-trained model, we explored the per-sample gradients of the model parameters relative to a task-specific loss, and constructed a linear model that combines gradients of model parameters and the activation of the model.</p>
            
          </div>      
        </div>
      </div>
      
  </DIV>
</DIV>

</body>