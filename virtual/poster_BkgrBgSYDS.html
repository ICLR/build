<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link"    href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" target="_blank"   href="https://iclr.6connex.com/event/VirtualEvent/">Sponsor Hall</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="about.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Tri Dao,
       
       Nimit Sohoni,
       
       Albert Gu,
       
       Matthew Eichhorn,
       
       Amit Blonder,
       
       Megan Leszczynski,
       
       Atri Rudra,
       
       Christopher Ré
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/e6c98a4caacf05eb4e3066b934931be05b8162f4.pdf">
           Paper
       </a>
       
       <a href="https://github.com/HazyResearch/learning-circuits" target="_blank"  class="card-link">
           Code
       </a>
       
       
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=BkgrBgSYDS">
           Reviews
       </a>

       <!--  -->
       <!-- <a href="" target="_blank"  class="card-link"> -->
       <!--   Slides -->
       <!-- </a> -->
       <!--  -->

       <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Video
       </a>

       <a href="chat.html?room=channel/paper_channel_BkgrBgSYDS" target="_blank"  class="card-link">
           Chat
       </a>

       


     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Modern neural network architectures use structured linear transformations, such as low-rank matrices, sparse matrices, permutations, and the Fourier transform, to improve inference speed and reduce memory usage compared to general linear maps. However, choosing which of the myriad structured transformations to use (and its associated parameterization) is a laborious task that requires trading off speed, space, and accuracy. We consider a different approach: we introduce a family of matrices called kaleidoscope matrices (K-matrices) that provably capture any structured matrix with near-optimal space (parameter) and time (arithmetic operation) complexity. We empirically validate that K-matrices can be automatically learned within end-to-end pipelines to replace hand-crafted procedures, in order to improve model quality. For example, replacing channel shuffles in ShuffleNet improves classification accuracy on ImageNet by up to 5%. K-matrices can also simplify hand-engineered pipelines---we replace filter bank feature computation in speech data preprocessing with a learnable kaleidoscope layer, resulting in only 0.4% loss in accuracy on the TIMIT speech recognition task. In addition, K-matrices can capture latent structure in models: for a challenging permuted image classification task, adding a K-matrix to a standard convolutional architecture can enable learning the latent permutation and improve accuracy by over 8 points. We provide a practically efficient implementation of our approach, and use K-matrices in a Transformer network to attain 36% faster end-to-end inference speed on a language translation task.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=structured matrices" class="text-secondary text-decoration-none">structured matrices</a>,
       
       <a href="papers.html?filter=keywords&search=efficient ML" class="text-secondary text-decoration-none">efficient ML</a>,
       
       <a href="papers.html?filter=keywords&search=algorithms" class="text-secondary text-decoration-none">algorithms</a>,
       
       <a href="papers.html?filter=keywords&search=butterfly matrices" class="text-secondary text-decoration-none">butterfly matrices</a>,
       
       <a href="papers.html?filter=keywords&search=arithmetic circuits" class="text-secondary text-decoration-none">arithmetic circuits</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_BkgrBgSYDS?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_SJem8lSFwB.html" class="text-muted">
              <h5 class="card-title" align="center">Dynamic Model Pruning with Feedback</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Tao Lin,
              
              Sebastian U. Stich,
              
              Luis Barba,
              
              Daniil Dmitriev,
              
              Martin Jaggi,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJem8lSFwB.png" width="80%"/></center>

            <!-- <p class="card-text"> Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at inference. We propose a novel model compression method that...</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HyxjOyrKvr.html" class="text-muted">
              <h5 class="card-title" align="center">Neural Epitome Search for Architecture-Agnostic Network Compression</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Daquan Zhou,
              
              Xiaojie Jin,
              
              Qibin Hou,
              
              Kaixin Wang,
              
              Jianchao Yang,
              
              Jiashi Feng,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HyxjOyrKvr.png" width="80%"/></center>

            <!-- <p class="card-text"> We present a novel neural network compression method which can reuse the parameters efficiently to reduce the model size.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HkgxW0EYDS.html" class="text-muted">
              <h5 class="card-title" align="center">Scalable Model Compression by Entropy Penalized Reparameterization</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Deniz Oktay,
              
              Johannes Ballé,
              
              Saurabh Singh,
              
              Abhinav Shrivastava,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HkgxW0EYDS.png" width="80%"/></center>

            <!-- <p class="card-text"> An end-to-end trainable model compression method optimizing accuracy jointly with the expected model size.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rkeu30EtvS.html" class="text-muted">
              <h5 class="card-title" align="center">Network Deconvolution</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Chengxi Ye,
              
              Matthew Evanusa,
              
              Hua He,
              
              Anton Mitrokhin,
              
              Tom Goldstein,
              
              James A. Yorke,
              
              Cornelia Fermuller,
              
              Yiannis Aloimonos,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rkeu30EtvS.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose a method called network deconvolution that resembles animal vision system to train convolution networks better.</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>