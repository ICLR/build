<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Double Neural Counterfactual Regret Minimization </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Browse</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="events.html">Events</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Extras</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="about.html">About</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       Double Neural Counterfactual Regret Minimization
     </h3>

     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Hui Li,
       
       Kailiang Hu,
       
       Shaohua Zhang,
       
       Yuan Qi,
       
       Le Song
       
     </h5>

     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>


       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/b8cc78ebf1ae64586fb7ed77793297f0a9b4a816.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=ByedzkrKvH">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>

       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>

       <a href="https://iclr.rocket.chat/channel/paper_channel_ByedzkrKvH" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Chat
         </button>
       </a>

       

       
     </center>

   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Counterfactual regret minimization (CFR) is a fundamental and effective technique for solving Imperfect Information Games (IIG). However, the original CFR algorithm only works for discrete states and action spaces, and the resulting strategy is maintained as a tabular representation. Such tabular representation limits the method from being directly applied to large games. In this paper, we propose a double neural representation for the IIGs, where one neural network represents the cumulative regret, and the other represents the average strategy.  Such neural representations allow us to avoid manual game abstraction and carry out end-to-end optimization. To make the learning efficient, we also developed several novel techniques including a robust sampling method and a mini-batch Monte Carlo Counterfactual Regret Minimization (MCCFR) method, which may be of independent interests.  Empirically, on games tractable to tabular approaches, neural strategies trained with our algorithm converge comparably to their tabular counterparts, and significantly outperform those based on deep reinforcement learning.  On extremely large games with billions of decision nodes, our approach achieved strong performance while using hundreds of times less memory than the tabular CFR. On head-to-head matches of hands-up no-limit texas hold&#39;em, our neural agent beat the strong agent ABS-CFR by $9.8\pm4.1$ chips per game. It&#39;s a successful application of neural CFR in large games.

       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="keyword_Counterfactual Regret Minimization.html" class="text-secondary text-decoration-none">Counterfactual Regret Minimization</a>,
       
       <a href="keyword_Imperfect Information game.html" class="text-secondary text-decoration-none">Imperfect Information game</a>,
       
       <a href="keyword_Neural Strategy.html" class="text-secondary text-decoration-none">Neural Strategy</a>,
       
       <a href="keyword_Deep Learning.html" class="text-secondary text-decoration-none">Deep Learning</a>,
       
       <a href="keyword_Robust Sampling.html" class="text-secondary text-decoration-none">Robust Sampling</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="jumbotron" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_ByedzkrKvH?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rJx4p3NYDB.html" class="text-muted">
              <h5 class="card-title" align="center">Lazy-CFR: fast and near-optimal regret minimization for extensive games with imperfect information</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Yichi Zhou,
              
              Tongzheng Ren,
              
              Jialian Li,
              
              Dong Yan,
              
              Jun Zhu,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rJx4p3NYDB.png" width="80%"/></center>

            <!-- <p class="card-text"> Counterfactual regret minimization (CFR) methods are effective for solving two-player zero-sum extensive games with imperfect information with  state-of-the-art results.  However,  the vanilla CFR has to traverse the whole game tree in each round, wh...</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_S1xCPJHtDB.html" class="text-muted">
              <h5 class="card-title" align="center">Model Based Reinforcement Learning for Atari</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Łukasz Kaiser,
              
              Mohammad Babaeizadeh,
              
              Piotr Miłos,
              
              Błażej Osiński,
              
              Roy H Campbell,
              
              Konrad Czechowski,
              
              Dumitru Erhan,
              
              Chelsea Finn,
              
              Piotr Kozakowski,
              
              Sergey Levine,
              
              Afroz Mohiuddin,
              
              Ryan Sepassi,
              
              George Tucker,
              
              Henryk Michalewski,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/S1xCPJHtDB.png" width="80%"/></center>

            <!-- <p class="card-text"> We use video prediction models, a model-based reinforcement learning algorithm and 2h of gameplay per game to train agents for 26 Atari games.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BJewlyStDr.html" class="text-muted">
              <h5 class="card-title" align="center">On Bonus Based Exploration Methods In The Arcade Learning Environment</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Adrien Ali Taiga,
              
              William Fedus,
              
              Marlos C. Machado,
              
              Aaron Courville,
              
              Marc G. Bellemare,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BJewlyStDr.png" width="80%"/></center>

            <!-- <p class="card-text"> We find that existing bonus-based exploration methods have not been able to address the exploration-exploitation trade-off in the Arcade Learning Environment. </p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_Bkl5kxrKDr.html" class="text-muted">
              <h5 class="card-title" align="center">A Generalized Training Approach for Multiagent Learning</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Paul Muller,
              
              Shayegan Omidshafiei,
              
              Mark Rowland,
              
              Karl Tuyls,
              
              Julien Perolat,
              
              Siqi Liu,
              
              Daniel Hennes,
              
              Luke Marris,
              
              Marc Lanctot,
              
              Edward Hughes,
              
              Zhe Wang,
              
              Guy Lever,
              
              Nicolas Heess,
              
              Thore Graepel,
              
              Remi Munos,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/Bkl5kxrKDr.png" width="80%"/></center>

            <!-- <p class="card-text"> This paper investigates a population-based training regime based on game-theoretic principles called Policy-Spaced Response Oracles (PSRO). PSRO is general in the sense that it (1) encompasses well-known algorithms such as fictitious play and double ...</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>